{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the training set and the validation set which have been already preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing dataset\n",
    "train = pd.read_csv(\"dataset/rand/train_rand_noout3.csv\")\n",
    "val1 = pd.read_csv(\"dataset/rand/train_val1_rand.csv\")\n",
    "val2 = pd.read_csv(\"dataset/rand/train_val2_rand.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the training input samples and the labels for all the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=train.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "X_val1=val1.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0'], axis=1)\n",
    "X_val2=val2.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0'], axis=1)\n",
    "\n",
    "y=train['NumberOfSales']\n",
    "y_val1=val1['NumberOfSales']\n",
    "y_val2=val2['NumberOfSales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to find good hyperparameter in Extremely Randomized Regressor. First of all we try to find good values for max_depth and max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.027840053245100645 0.0195790631428\n"
     ]
    }
   ],
   "source": [
    "nt=100\n",
    "best_ma = 1000000\n",
    "\n",
    "for depth in range(18,28,2):\n",
    "    for na in range(10,17,1):\n",
    "        \n",
    "        forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "        forest.fit(X, y)\n",
    "        \n",
    "        y_pred=forest.predict(X_val1)\n",
    "        mse_val1=mean_squared_error(y_val1,y_pred)\n",
    "        mae_val1=mean_absolute_error(y_val1,y_pred)\n",
    "        \n",
    "        if(mae_val1 < best_ma):\n",
    "            best_ma = mae_val1\n",
    "            best_depth = depth\n",
    "            best_na = na\n",
    "       \n",
    "        print(\"na= \", na, \" depth= \", depth, \" rmse= \", sqrt(mse_val1),\" mae= \", mae_val1)\n",
    "\n",
    "print(\"best_na= \", best_na, \" best_depth= \", best_depth, \" best_ma= \", best_ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check if removing some features we obtain a lower validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsHoliday 0.027461465475176503 0.0192611161096\n",
      "HasPromotions 0.04003863317247128 0.029766546966\n",
      "StoreType 0.027824418374292902 0.0196920401725\n",
      "NearestCompetitor 0.027584527895542416 0.0195318982325\n",
      "Region_AreaKM2 0.027287162569294057 0.0192372364336\n",
      "Region_GDP 0.027523689189593494 0.0194295830634\n",
      "Region_PopulationK 0.027428748102158052 0.0193894669588\n",
      "CloudCover 0.02733722499481307 0.0192063738651\n",
      "Max_Dew_PointC 0.02734089359584064 0.0192392218557\n",
      "Max_Gust_SpeedKm_h 0.02725703009834444 0.0191719622117\n",
      "Max_Humidity 0.027307794024024164 0.0191720375717\n",
      "Max_Sea_Level_PressurehPa 0.027238982352806453 0.0191068415829\n",
      "Max_TemperatureC 0.027197144724387872 0.0190890521565\n",
      "Max_VisibilityKm 0.027483600412522943 0.0193079902133\n",
      "Max_Wind_SpeedKm_h 0.027304641339577194 0.0192076982416\n",
      "Mean_Dew_PointC 0.027335722822490284 0.0192455729875\n",
      "Mean_Humidity 0.027260259474371412 0.0191488758657\n",
      "Mean_Sea_Level_PressurehPa 0.027213049351888646 0.0191415247333\n",
      "Mean_TemperatureC 0.027269236731764512 0.0191657947449\n",
      "Mean_VisibilityKm 0.027406705419735052 0.0192643655426\n",
      "Mean_Wind_SpeedKm_h 0.02727299807713253 0.0191596730741\n",
      "Min_Dew_PointC 0.027362512952677182 0.0192436223025\n",
      "Min_Humidity 0.02728539811226626 0.0191673468957\n",
      "Min_Sea_Level_PressurehPa 0.02721954371874126 0.0191245727561\n",
      "Min_TemperatureC 0.027338797874671618 0.0192465245755\n",
      "Min_VisibilitykM 0.02714203031140611 0.0190631585227\n",
      "Precipitationmm 0.027256540403540856 0.0191327427223\n",
      "WindDirDegrees 0.027328467661340818 0.0192622508747\n",
      "AssortmentType_With Fish Department 0.02728386159875894 0.0191857183292\n",
      "AssortmentType_With Non-Food Department 0.027813581190119497 0.0197255356071\n",
      "Rain 0.02731586852901611 0.0191710597015\n",
      "Snow 0.027322724812975385 0.0192568472793\n",
      "Fog 0.027301383779820165 0.0192336420648\n",
      "Hail 0.027286380618007096 0.01919812971\n",
      "Thunderstorm 0.02736712631215594 0.019228356041\n",
      "IsSaturday 0.027678034152288387 0.0196219312509\n",
      "IsSunday 0.028126080501693303 0.0195136724196\n",
      "WasOpenYesterday 0.03167365049908015 0.0223334353932\n",
      "IsOpenTomorrow 0.02759745485766599 0.0194780934861\n",
      "MeanMonthSales 0.027121560150161705 0.0191170739796\n",
      "MeanStoreSales 0.04366230079060289 0.0313677711262\n"
     ]
    }
   ],
   "source": [
    "nt=100\n",
    "na=best_na\n",
    "depth=best_depth\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "for feature in feature_names:\n",
    "    X=df_train_clear.drop(['StoreID','NumberOfSales','NumberOfCustomers'], axis=1)\n",
    "    X_val1=df_val1_clear.drop(['StoreID','NumberOfSales','NumberOfCustomers'], axis=1)\n",
    "    X=X.drop([feature], axis=1)\n",
    "    X_val1=X_val1.drop([feature], axis=1)\n",
    "    forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "    forest.fit(X, y)\n",
    "    y_pred=forest.predict(X_val1)\n",
    "    mse_val1=mean_squared_error(y_val1,y_pred)\n",
    "    mae_val1=mean_absolute_error(y_val1,y_pred)\n",
    "    print(feature, sqrt(mse_val1), mae_val1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the worst features and we compute the validation error using the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "worst_features = []\n",
    "\n",
    "X=df_train_clear.drop(['StoreID','NumberOfSales','NumberOfCustomers'], axis=1)\n",
    "X_val1=df_val1_clear.drop(['StoreID','NumberOfSales','NumberOfCustomers'], axis=1)\n",
    "X=X.drop(worst_features, axis=1)\n",
    "X_val1=X_val1.drop(worst_features, axis=1)\n",
    "forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "forest.fit(X, y)\n",
    "\n",
    "y_pred=forest.predict(X_val1)\n",
    "mse_val1=mean_squared_error(y_val1,y_pred)\n",
    "mae_val1=mean_absolute_error(y_val1,y_pred)\n",
    "print(\"rmse= \",sqrt(mse_val1), \" mae= \", mae_val1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we optimize the number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_ma = 1000000\n",
    "na=best_na\n",
    "depth=best_depth\n",
    "\n",
    "for nt in range(50,200,25):\n",
    "        \n",
    "    forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "    forest.fit(X, y)\n",
    "\n",
    "    y_pred=forest.predict(X_val1)\n",
    "    mse_val1=mean_squared_error(y_val1,y_pred)\n",
    "    mae_val1=mean_absolute_error(y_val1,y_pred)\n",
    "\n",
    "    if(mae_val1 < best_ma):\n",
    "        best_ma = mae_val1\n",
    "        best_nt = nt\n",
    "\n",
    "    print(\"nt= \", nt, sqrt(mse_val1),\" mae= \", mae_val1)\n",
    "\n",
    "print(\"best_nt= \", best_nt, \" best_ma= \", best_ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we predict the second validation set and we compute the mean square error and the mean absolute errorNow we predict the second validation set and we compute the mean square error and the mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_depth = \n",
    "best_na = \n",
    "best_nt =\n",
    "  \n",
    "forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "forest.fit(X, y)\n",
    "    \n",
    "xclas.fit(X, y)   \n",
    "y_pred_val2 = xclas.predict(X_val2) \n",
    "mse_val1=mean_squared_error(y_val2,y_pred_val2)\n",
    "mae_val1=mean_absolute_error(y_val2,y_pred_val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end we save the predicted values in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns=['Date', 'StoreID', 'RegionID', 'SalesPredicted', 'SalesReal']\n",
    "index=range(y_val2.shape[0])\n",
    "result=pd.DataFrame(index=index,columns=columns)\n",
    "\n",
    "result['Date']=val2['Date']\n",
    "result['StoreID']=val2['StoreID']\n",
    "result['RegionID']=val2['Region']\n",
    "result['SalesPredicted']=y_pred_val2\n",
    "result['SalesReal']=y_val2\n",
    "\n",
    "result.to_csv(\"results.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
