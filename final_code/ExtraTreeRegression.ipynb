{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the training set and the validation set which have been already preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dataset\n",
    "train = pd.read_csv(\"dataset/processed/train_rand.csv\", index_col=0)\n",
    "val = pd.read_csv(\"dataset/processed/val1_rand.csv\", index_col=0)\n",
    "test = pd.read_csv(\"dataset/processed/val2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.OrdinalDate = train.OrdinalDate.map(lambda x: x % 365)\n",
    "val.OrdinalDate = val.OrdinalDate.map(lambda x: x % 365)\n",
    "test.OrdinalDate = test.OrdinalDate.map(lambda x: x % 365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the training input samples and the labels for all the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['NumberOfSales']\n",
    "y_val1=val['NumberOfSales']\n",
    "y_val2=test['NumberOfSales']\n",
    "\n",
    "X=train.drop(['StoreID','Date', 'NumberOfSales', 'Region'], axis=1)\n",
    "X_val1=val.drop(['StoreID','Date', 'NumberOfSales', 'Region'], axis=1)\n",
    "X_val2=test.drop(['StoreID','Date', 'NumberOfSales', 'Region'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to find good hyperparameter in Extremely Randomized Regressor. First of all we try to find good values for max_depth and max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na=  15  depth=  35  mae=  392.9575211698765\n",
      "na=  17  depth=  35  mae=  393.4805472584526\n",
      "na=  19  depth=  35  mae=  395.2070347529328\n",
      "na=  21  depth=  35  mae=  394.87881238365276\n",
      "na=  23  depth=  35  mae=  394.5399960661282\n",
      "na=  15  depth=  37  mae=  392.7001126232367\n",
      "na=  17  depth=  37  mae=  392.9004105457858\n",
      "na=  19  depth=  37  mae=  394.0109684714265\n",
      "na=  21  depth=  37  mae=  393.9910319242007\n",
      "na=  23  depth=  37  mae=  395.24315332547053\n",
      "na=  15  depth=  39  mae=  392.2170056738749\n",
      "na=  17  depth=  39  mae=  393.1242348756863\n",
      "na=  19  depth=  39  mae=  393.495005715599\n",
      "na=  21  depth=  39  mae=  393.96618393774804\n",
      "na=  23  depth=  39  mae=  394.1184020831948\n",
      "na=  15  depth=  41  mae=  391.875723497066\n",
      "na=  17  depth=  41  mae=  393.5910562051734\n",
      "na=  19  depth=  41  mae=  394.38242491745166\n",
      "na=  21  depth=  41  mae=  393.8198681241312\n",
      "na=  23  depth=  41  mae=  394.72285930969673\n",
      "na=  15  depth=  43  mae=  393.49224503441854\n",
      "na=  17  depth=  43  mae=  393.0707207825673\n",
      "na=  19  depth=  43  mae=  393.59882729204827\n",
      "na=  21  depth=  43  mae=  394.6462832235602\n",
      "na=  23  depth=  43  mae=  394.8851591645094\n",
      "best_na=  15  best_depth=  41  best_ma=  391.875723497066\n"
     ]
    }
   ],
   "source": [
    "nt=100\n",
    "best_ma = 1000000\n",
    "\n",
    "for depth in range(35,45,2):\n",
    "    for na in range(15,25,2):\n",
    "        \n",
    "        forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "        forest.fit(X, y)\n",
    "        \n",
    "        y_pred=forest.predict(X_val1)\n",
    "        mae_val1=mean_absolute_error(y_val1,y_pred)\n",
    "        \n",
    "        if(mae_val1 < best_ma):\n",
    "            best_ma = mae_val1\n",
    "            best_depth = depth\n",
    "            best_na = na\n",
    "       \n",
    "        print(\"na= \", na, \" depth= \", depth, \" mae= \", mae_val1)\n",
    "\n",
    "print(\"best_na= \", best_na, \" best_depth= \", best_depth, \" best_ma= \", best_ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check if removing some features we obtain a lower validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StoreID', 'Date', 'IsHoliday', 'HasPromotions', 'StoreType',\n",
       "       'NearestCompetitor', 'Region', 'NumberOfSales', 'Region_AreaKM2',\n",
       "       'Region_GDP', 'Region_PopulationK', 'CloudCover', 'Max_Dew_PointC',\n",
       "       'Max_Gust_SpeedKm_h', 'Max_Humidity', 'Max_Sea_Level_PressurehPa',\n",
       "       'Max_TemperatureC', 'Max_VisibilityKm', 'Max_Wind_SpeedKm_h',\n",
       "       'Mean_Dew_PointC', 'Mean_Humidity', 'Mean_Sea_Level_PressurehPa',\n",
       "       'Mean_TemperatureC', 'Mean_VisibilityKm', 'Mean_Wind_SpeedKm_h',\n",
       "       'Min_Dew_PointC', 'Min_Humidity', 'Min_Sea_Level_PressurehPa',\n",
       "       'Min_TemperatureC', 'Min_VisibilitykM', 'Precipitationmm',\n",
       "       'WindDirDegrees', 'AssortmentType_With Fish Department',\n",
       "       'AssortmentType_With Non-Food Department', 'Rain', 'Snow', 'Fog',\n",
       "       'Hail', 'Thunderstorm', 'IsSaturday', 'IsSunday', 'OrdinalDate',\n",
       "       'WasOpenYesterday', 'IsOpenTomorrow', 'MeanMonthSales',\n",
       "       'MeanStoreSales', 'StdStoreSales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsHoliday 394.04614160148236\n",
      "HasPromotions 466.71342997348034\n",
      "StoreType 397.6493085726903\n",
      "NearestCompetitor 397.98747313305046\n",
      "Region_AreaKM2 393.1670051081153\n",
      "Region_GDP 393.4981575283256\n",
      "Region_PopulationK 393.8225351874293\n",
      "CloudCover 392.8573209373665\n",
      "Max_Dew_PointC 394.4272645211077\n",
      "Max_Gust_SpeedKm_h 393.4433704298983\n",
      "Max_Humidity 392.8910008340378\n",
      "Max_Sea_Level_PressurehPa 393.76407495518555\n",
      "Max_TemperatureC 393.79952635121833\n",
      "Max_VisibilityKm 393.8495152559683\n",
      "Max_Wind_SpeedKm_h 393.02884426213876\n",
      "Mean_Dew_PointC 393.6829461482509\n",
      "Mean_Humidity 393.723647210618\n",
      "Mean_Sea_Level_PressurehPa 393.3813708424867\n",
      "Mean_TemperatureC 393.30082365847176\n",
      "Mean_VisibilityKm 392.4378063724292\n",
      "Mean_Wind_SpeedKm_h 393.8634596997554\n",
      "Min_Dew_PointC 392.75327675812696\n",
      "Min_Humidity 392.8219941450898\n",
      "Min_Sea_Level_PressurehPa 393.5966943074798\n",
      "Min_TemperatureC 393.2227286994512\n",
      "Min_VisibilitykM 393.53479979055135\n",
      "Precipitationmm 393.65978668800585\n",
      "WindDirDegrees 393.8310924524156\n",
      "AssortmentType_With Fish Department 393.0132159517472\n",
      "AssortmentType_With Non-Food Department 391.24118503591427\n",
      "Rain 393.0362798227788\n",
      "Snow 393.27821386446345\n",
      "Fog 393.5408043709631\n",
      "Hail 392.45120027220185\n",
      "Thunderstorm 392.6382587890207\n",
      "IsSaturday 400.479241129572\n",
      "IsSunday 400.51777474176237\n",
      "OrdinalDate 398.3573906743943\n",
      "WasOpenYesterday 418.8495764798921\n",
      "IsOpenTomorrow 395.3596549192944\n",
      "MeanMonthSales 401.10815985199963\n",
      "MeanStoreSales 486.97421025811013\n",
      "StdStoreSales 416.0027785319682\n",
      "AssortmentType_With Non-Food Department 391.24118503591427\n"
     ]
    }
   ],
   "source": [
    "nt=100\n",
    "na=best_na\n",
    "depth=best_depth\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "feature_best = ''\n",
    "mae_best = 10000000\n",
    "\n",
    "for feature in feature_names:\n",
    "    X_t=X[feature]\n",
    "    X_val_t=X_val1[feature]\n",
    "    X_f = X.drop([feature], axis=1)\n",
    "    X_val_f = X_val1.drop([feature], axis=1)\n",
    "\n",
    "    forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "    forest.fit(X_f, y)\n",
    "\n",
    "    y_pred = forest.predict(X_val_f)\n",
    "    mae = mean_absolute_error(y_val1, y_pred)\n",
    "\n",
    "    print(feature, mae)\n",
    "\n",
    "    if( mae < mae_best ):\n",
    "        feature_best = feature\n",
    "        mae_best = mae\n",
    "    X[feature]=X_t\n",
    "    X_val1[feature]=X_val_t\n",
    "    \n",
    "print(feature_best, mae_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no feature has to be removed, since the mae doesn't decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we optimize the number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt=  50  mae=  394.6453441452038\n",
      "nt=  75  mae=  392.9002934538834\n",
      "nt=  100  mae=  391.875723497066\n",
      "nt=  125  mae=  391.70320399632544\n",
      "nt=  150  mae=  391.34359623808\n",
      "nt=  175  mae=  390.94026819713184\n",
      "nt=  200  mae=  390.7971728092944\n",
      "best_nt=  200  best_ma=  390.7971728092944\n"
     ]
    }
   ],
   "source": [
    "best_ma = 1000000\n",
    "na=best_na\n",
    "depth=best_depth\n",
    "\n",
    "X=train.drop(['StoreID','Date', 'NumberOfSales', 'Region'], axis=1)\n",
    "X_val1=val.drop(['StoreID','Date', 'NumberOfSales', 'Region'], axis=1)\n",
    "\n",
    "for nt in range(50,201,25):\n",
    "        \n",
    "    forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "    forest.fit(X, y)\n",
    "\n",
    "    y_pred=forest.predict(X_val1)\n",
    "    mae_val1=mean_absolute_error(y_val1,y_pred)\n",
    "\n",
    "    if(mae_val1 < best_ma):\n",
    "        best_ma = mae_val1\n",
    "        best_nt = nt\n",
    "\n",
    "    print(\"nt= \", nt, \" mae= \", mae_val1)\n",
    "\n",
    "print(\"best_nt= \", best_nt, \" best_ma= \", best_ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we predict the second validation set and we compute the mean square error and the mean absolute errorNow we predict the second validation set and we compute the mean square error and the mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt=200\n",
    "forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "forest.fit(X, y)\n",
    "    \n",
    "y_pred_val2 = forest.predict(X_val2) \n",
    "mae_val2=mean_absolute_error(y_val2,y_pred_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585.8973912216871"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_val2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end we save the predicted values in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Date', 'StoreID', 'RegionID', 'SalesPredicted', 'SalesReal']\n",
    "index=range(y_val2.shape[0])\n",
    "result=pd.DataFrame(index=index,columns=columns)\n",
    "\n",
    "result['Date']=test['Date']\n",
    "result['StoreID']=test['StoreID']\n",
    "result['RegionID']=test['Region']\n",
    "result['SalesPredicted']=y_pred_val2\n",
    "result['SalesReal']=y_val2\n",
    "\n",
    "result.to_csv(\"results_et.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
