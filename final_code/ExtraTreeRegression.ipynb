{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the training set and the validation set which have been already preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dataset\n",
    "train = pd.read_csv(\"dataset/rand/train_rand_noout3.csv\")\n",
    "val1 = pd.read_csv(\"dataset/rand/train_val1_rand.csv\")\n",
    "val2 = pd.read_csv(\"dataset/rand/train_val2_rand.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the training input samples and the labels for all the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "X_val1=val1.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0'], axis=1)\n",
    "X_val2=val2.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0'], axis=1)\n",
    "\n",
    "y=train['NumberOfSales']\n",
    "y_val1=val1['NumberOfSales']\n",
    "y_val2=val2['NumberOfSales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to find good hyperparameter in Extremely Randomized Regressor. First of all we try to find good values for max_depth and max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "na=  15  depth=  35  mae=  382.74758148414526\n",
      "na=  17  depth=  35  mae=  382.3938838421324\n",
      "na=  19  depth=  35  mae=  382.71543965437496\n",
      "na=  21  depth=  35  mae=  382.45078025818196\n",
      "na=  23  depth=  35  mae=  382.27087371263565\n",
      "na=  15  depth=  37  mae=  383.7711026686291\n",
      "na=  17  depth=  37  mae=  382.12676173537875\n",
      "na=  19  depth=  37  mae=  382.5523383456669\n",
      "na=  21  depth=  37  mae=  382.21789490984906\n",
      "na=  23  depth=  37  mae=  381.9982617692045\n",
      "na=  15  depth=  39  mae=  382.234124666574\n",
      "na=  17  depth=  39  mae=  382.23289550399204\n",
      "na=  19  depth=  39  mae=  381.3113760725615\n",
      "na=  21  depth=  39  mae=  382.1435051457042\n",
      "na=  23  depth=  39  mae=  382.5049578511858\n",
      "na=  15  depth=  41  mae=  382.98362671602666\n",
      "na=  17  depth=  41  mae=  382.9317984771984\n",
      "na=  19  depth=  41  mae=  382.092979433625\n",
      "na=  21  depth=  41  mae=  382.0612857317109\n",
      "na=  23  depth=  41  mae=  381.7750098555154\n",
      "na=  15  depth=  43  mae=  382.3472753026699\n",
      "na=  17  depth=  43  mae=  382.39098832803325\n",
      "na=  19  depth=  43  mae=  383.2383388835402\n",
      "na=  21  depth=  43  mae=  382.00340934437503\n",
      "na=  23  depth=  43  mae=  382.7162994280876\n",
      "best_na=  19  best_depth=  39  best_ma=  381.3113760725615\n"
     ]
    }
   ],
   "source": [
    "nt=100\n",
    "best_ma = 1000000\n",
    "\n",
    "for depth in range(35,45,2):\n",
    "    for na in range(15,25,2):\n",
    "        \n",
    "        forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "        forest.fit(X, y)\n",
    "        \n",
    "        y_pred=forest.predict(X_val1)\n",
    "        mae_val1=mean_absolute_error(y_val1,y_pred)\n",
    "        \n",
    "        if(mae_val1 < best_ma):\n",
    "            best_ma = mae_val1\n",
    "            best_depth = depth\n",
    "            best_na = na\n",
    "       \n",
    "        print(\"na= \", na, \" depth= \", depth, \" mae= \", mae_val1)\n",
    "\n",
    "print(\"best_na= \", best_na, \" best_depth= \", best_depth, \" best_ma= \", best_ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check if removing some features we obtain a lower validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'StoreID', 'Date', 'IsHoliday',\n",
       "       'HasPromotions', 'StoreType', 'NearestCompetitor', 'Region',\n",
       "       'NumberOfSales', 'Region_AreaKM2', 'Region_GDP', 'Region_PopulationK',\n",
       "       'CloudCover', 'Max_Dew_PointC', 'Max_Gust_SpeedKm_h', 'Max_Humidity',\n",
       "       'Max_Sea_Level_PressurehPa', 'Max_TemperatureC', 'Max_VisibilityKm',\n",
       "       'Max_Wind_SpeedKm_h', 'Mean_Dew_PointC', 'Mean_Humidity',\n",
       "       'Mean_Sea_Level_PressurehPa', 'Mean_TemperatureC', 'Mean_VisibilityKm',\n",
       "       'Mean_Wind_SpeedKm_h', 'Min_Dew_PointC', 'Min_Humidity',\n",
       "       'Min_Sea_Level_PressurehPa', 'Min_TemperatureC', 'Min_VisibilitykM',\n",
       "       'Precipitationmm', 'WindDirDegrees',\n",
       "       'AssortmentType_With Fish Department',\n",
       "       'AssortmentType_With Non-Food Department', 'Rain', 'Snow', 'Fog',\n",
       "       'Hail', 'Thunderstorm', 'IsSaturday', 'IsSunday', 'OrdinalDate',\n",
       "       'WasOpenYesterday', 'IsOpenTomorrow', 'MeanMonthSales',\n",
       "       'MeanStoreSales', 'StdStoreSales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsHoliday 383.2106390048167\n",
      "HasPromotions 441.421560992092\n",
      "StoreType 386.50050645499346\n",
      "NearestCompetitor 386.35500230610506\n",
      "Region_AreaKM2 383.07445813521247\n",
      "Region_GDP 382.3052043723652\n",
      "Region_PopulationK 382.21952977049017\n",
      "CloudCover 381.4321742952659\n",
      "Max_Dew_PointC 381.6206864966225\n",
      "Max_Gust_SpeedKm_h 382.95921967431866\n",
      "Max_Humidity 381.3096846727071\n",
      "Max_Sea_Level_PressurehPa 382.3474022228836\n",
      "Max_TemperatureC 382.10538181906304\n",
      "Max_VisibilityKm 381.73256768653243\n",
      "Mean_Dew_PointC 381.7931124676994\n",
      "Mean_Humidity 381.51640427151796\n",
      "Mean_Sea_Level_PressurehPa 381.53636759749406\n",
      "Mean_TemperatureC 382.3282120240661\n",
      "Mean_VisibilityKm 381.53245735088785\n",
      "Mean_Wind_SpeedKm_h 381.83862469617264\n",
      "Min_Dew_PointC 381.7677101128991\n",
      "Min_Humidity 382.30797464586044\n",
      "Min_Sea_Level_PressurehPa 381.9452656171194\n",
      "Min_TemperatureC 382.078137095699\n",
      "Min_VisibilitykM 381.58014700419915\n",
      "Precipitationmm 382.1030211246323\n",
      "WindDirDegrees 382.30336044467623\n",
      "AssortmentType_With Fish Department 381.59739299990116\n",
      "AssortmentType_With Non-Food Department 381.9547147706205\n",
      "Rain 382.12582096845176\n",
      "Snow 381.3845829123168\n",
      "Fog 380.50171312060854\n",
      "Hail 382.17675304357965\n",
      "Thunderstorm 381.80058406263083\n",
      "IsSaturday 389.9493476532034\n",
      "IsSunday 387.5865456123957\n",
      "OrdinalDate 394.6023149743823\n",
      "WasOpenYesterday 406.7984039759609\n",
      "IsOpenTomorrow 384.05552803064387\n",
      "MeanMonthSales 395.3219675443612\n",
      "MeanStoreSales 445.8350323146762\n",
      "StdStoreSales 398.7064874750819\n",
      "Fog 380.50171312060854\n"
     ]
    }
   ],
   "source": [
    "nt=100\n",
    "na=best_na\n",
    "depth=best_depth\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "feature_best = ''\n",
    "mae_best = 10000000\n",
    "\n",
    "for feature in feature_names:\n",
    "    X_t=X[feature]\n",
    "    X_val_t=X_val1[feature]\n",
    "    X_f = X.drop([feature], axis=1)\n",
    "    X_val_f = X_val1.drop([feature], axis=1)\n",
    "\n",
    "    forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "    forest.fit(X_f, y)\n",
    "\n",
    "    y_pred = forest.predict(X_val_f)\n",
    "    mae = mean_absolute_error(y_val1, y_pred)\n",
    "\n",
    "    print(feature, mae)\n",
    "\n",
    "    if( mae < mae_best ):\n",
    "        feature_best = feature\n",
    "        mae_best = mae\n",
    "    X[feature]=X_t\n",
    "    X_val1[feature]=X_val_t\n",
    "    \n",
    "print(feature_best, mae_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no feature has to be removed, since the mae doesn't decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we optimize the number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt=  50  mae=  383.87710742530186\n",
      "nt=  75  mae=  382.28112826067644\n",
      "nt=  100  mae=  381.3113760725615\n",
      "nt=  125  mae=  380.8787501284567\n",
      "nt=  150  mae=  380.4206270358552\n",
      "nt=  175  mae=  380.1149443087992\n",
      "best_nt=  175  best_ma=  380.1149443087992\n"
     ]
    }
   ],
   "source": [
    "best_ma = 1000000\n",
    "na=best_na\n",
    "depth=best_depth\n",
    "\n",
    "X=train.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "X_val1=val1.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0'], axis=1)\n",
    "\n",
    "for nt in range(50,200,25):\n",
    "        \n",
    "    forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "    forest.fit(X, y)\n",
    "\n",
    "    y_pred=forest.predict(X_val1)\n",
    "    mae_val1=mean_absolute_error(y_val1,y_pred)\n",
    "\n",
    "    if(mae_val1 < best_ma):\n",
    "        best_ma = mae_val1\n",
    "        best_nt = nt\n",
    "\n",
    "    print(\"nt= \", nt, \" mae= \", mae_val1)\n",
    "\n",
    "print(\"best_nt= \", best_nt, \" best_ma= \", best_ma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we predict the second validation set and we compute the mean square error and the mean absolute errorNow we predict the second validation set and we compute the mean square error and the mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt=200\n",
    "forest = ExtraTreesRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "forest.fit(X, y)\n",
    "    \n",
    "y_pred_val2 = forest.predict(X_val2) \n",
    "mae_val2=mean_absolute_error(y_val2,y_pred_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585.1358403156978"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_val2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end we save the predicted values in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Date', 'StoreID', 'RegionID', 'SalesPredicted', 'SalesReal']\n",
    "index=range(y_val2.shape[0])\n",
    "result=pd.DataFrame(index=index,columns=columns)\n",
    "\n",
    "result['Date']=val2['Date']\n",
    "result['StoreID']=val2['StoreID']\n",
    "result['RegionID']=val2['Region']\n",
    "result['SalesPredicted']=y_pred_val2\n",
    "result['SalesReal']=y_val2\n",
    "\n",
    "result.to_csv(\"results.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
