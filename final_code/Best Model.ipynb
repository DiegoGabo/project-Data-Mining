{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from math import sqrt\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the preprocessed dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_no_val2 = pd.read_csv(\"../dataset/processed1/train_no_val2.csv\")\n",
    "train_no_val1 = train_no_val2.loc[(train_no_val2['Date']<'2017-11-01')]\n",
    "train_complete = pd.read_csv(\"../dataset/processed1/train.csv\")\n",
    "\n",
    "val1 = train_no_val2.loc[((train_no_val2['Date']>='2017-11-01') & (train_no_val2['Date']<='2017-12-31'))]\n",
    "val2 = pd.read_csv(\"../dataset/processed1/val2.csv\")\n",
    "\n",
    "test = pd.read_csv(\"../dataset/processed1/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_no_val1.OrdinalDate = train_no_val1.OrdinalDate.map(lambda x: x % 365)\n",
    "train_no_val2.OrdinalDate = train_no_val2.OrdinalDate.map(lambda x: x % 365)\n",
    "train_complete.OrdinalDate = train_complete.OrdinalDate.map(lambda x: x % 365)\n",
    "\n",
    "val1.OrdinalDate = val1.OrdinalDate.map(lambda x: x % 365)\n",
    "val2.OrdinalDate = val2.OrdinalDate.map(lambda x: x % 365)\n",
    "\n",
    "test.OrdinalDate = test.OrdinalDate.map(lambda x: x % 365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing train-val-test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_no_val1 = train_no_val1['NumberOfSales']\n",
    "y_train_no_val2 = train_no_val2['NumberOfSales']\n",
    "y_train_complete = train_complete['NumberOfSales']\n",
    "\n",
    "y_val1 = val1['NumberOfSales']\n",
    "y_val2 = val2['NumberOfSales']\n",
    "\n",
    "X_train_no_val1 = train_no_val1.drop(['StoreID','Date', 'NumberOfSales', 'Region'], axis=1)\n",
    "X_train_no_val2 = train_no_val2.drop(['StoreID','Date', 'NumberOfSales', 'Region'], axis=1)\n",
    "X_train_complete = train_complete.drop(['StoreID','Date', 'NumberOfSales', 'Region'], axis=1)\n",
    "\n",
    "X_val1 = val1.drop(['StoreID','Date', 'NumberOfSales', 'Region'], axis=1)\n",
    "X_val2 = val2.drop(['StoreID','Date', 'NumberOfSales', 'Region'], axis=1)\n",
    "\n",
    "X_test = test.drop(['StoreID','Date', 'NumberOfSales', 'Region'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(max_depth=40, random_state=0, n_estimators=100, max_features=21, n_jobs=-1)\n",
    "forest.fit(X_train_no_val1, y_train_no_val1)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train_no_val1.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], X_train_no_val1.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(num=None, figsize=(14, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train_no_val1.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train_no_val1.shape[1]), X_train_no_val1.columns[indices] ,rotation=90)\n",
    "plt.xlim([-1, X_train_no_val1.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_selection_model = SelectFromModel(forest, threshold=0.0065, prefit=True)\n",
    "\n",
    "X_train_no_val1 = feature_selection_model.transform(X_train_no_val1)\n",
    "X_train_no_val2 = feature_selection_model.transform(X_train_no_val2)\n",
    "X_train_complete = feature_selection_model.transform(X_train_complete)\n",
    "\n",
    "X_val1 = feature_selection_model.transform(X_val1)\n",
    "X_val2 = feature_selection_model.transform(X_val2)\n",
    "\n",
    "X_test = feature_selection_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute the model for val2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function used to compute the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcola_errore(ypred, y, val):\n",
    "    val=val.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "\n",
    "    columns=['Date', 'StoreID', 'RegionID', 'SalesPredicted', 'SalesReal']\n",
    "    index=range(y.shape[0])\n",
    "    result=pd.DataFrame(index=index,columns=columns)\n",
    "\n",
    "    result['Date']=val['Date']\n",
    "    result['StoreID']=val['StoreID']\n",
    "    result['RegionID']=val['Region']\n",
    "    result['SalesPredicted']=ypred\n",
    "    result['SalesReal']=y\n",
    "    \n",
    "\n",
    "    # Transform dates from '%Y-%m-%d' to datetime objects.\n",
    "    def transform_date(x):\n",
    "        date = datetime.datetime.strptime(x, '%Y-%m-%d')\n",
    "        return date\n",
    "\n",
    "    result['Date'] = result['Date'].map(transform_date)\n",
    "    result['Month'] = result.Date.map(lambda d: d.strftime('%Y-%m'))\n",
    "    result = result.groupby(['StoreID', 'RegionID', 'Month']).sum().reset_index()[['Month', 'StoreID', 'RegionID', 'SalesPredicted', 'SalesReal']]\n",
    "\n",
    "    result['SalesError'] = abs(result.SalesPredicted - result.SalesReal)\n",
    "\n",
    "    region_error = (result.groupby('RegionID').sum().SalesError / result.groupby('RegionID').sum().SalesReal).reset_index().rename(columns={0: 'RegionError'}).set_index('RegionID')\n",
    "    total_error = np.mean(region_error.RegionError)\n",
    "    return total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#best parameters\n",
    "na=4\n",
    "depth=15\n",
    "nt=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "forest.fit(X_train_no_val2, y_train_no_val2)\n",
    "\n",
    "y_pred_val2 = forest.predict(X_val2)\n",
    "\n",
    "mae = mean_absolute_error(y_val2, y_pred_val2)\n",
    "e = calcola_errore(y_pred_val2, y_val2, val2)\n",
    "\n",
    "print(mae, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns=['Date', 'StoreID', 'RegionID', 'SalesPredicted', 'SalesReal']\n",
    "index=range(y_val2.shape[0])\n",
    "\n",
    "val2 = val2.reset_index(drop=True)\n",
    "y_val2 = y_val2.reset_index(drop=True)\n",
    "\n",
    "result_val2=pd.DataFrame(index=index,columns=columns)\n",
    "\n",
    "result_val2['Date']=val2['Date']\n",
    "result_val2['StoreID']=val2['StoreID']\n",
    "result_val2['RegionID']=val2['Region']\n",
    "result_val2['SalesPredicted']=y_pred_val2\n",
    "result_val2['SalesReal']=y_val2\n",
    "\n",
    "def transform_date(x):\n",
    "    date = datetime.datetime.strptime(x, '%Y-%m-%d')\n",
    "    return date\n",
    "\n",
    "result_val2['Date'] = result_val2['Date'].map(transform_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "def estimate_sales(x):\n",
    "    store = x['StoreID']\n",
    "    month = x['Date'].month\n",
    "    sales = x['SalesPredicted']\n",
    "    if (store, month) in d.keys():\n",
    "        d[(store, month)] += sales\n",
    "    else:\n",
    "        d[(store, month)] = sales\n",
    "        \n",
    "result_val2.loc[:, ['StoreID', 'Date', 'SalesPredicted']].apply(estimate_sales, axis=1)\n",
    "\n",
    "d1 = {'StoreID':[], 'Month':[], 'NumberOfSales':[]}\n",
    "\n",
    "for s,m in d.keys():\n",
    "    d1['StoreID'].append(s)\n",
    "    d1['Month'].append(m)\n",
    "    d1['NumberOfSales'].append(d[(s,m)])\n",
    "    \n",
    "final_result_val2 = pd.DataFrame(d1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute the model for the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(max_depth=depth, random_state=0, n_estimators=nt, max_features=na, n_jobs=-1)\n",
    "forest.fit(X_train_complete, y_train_complete)\n",
    "\n",
    "y_pred_test = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns=['Date', 'StoreID', 'RegionID', 'SalesPredicted', 'SalesReal']\n",
    "index=range(test.shape[0])\n",
    "\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "result_test=pd.DataFrame(index=index,columns=columns)\n",
    "\n",
    "result_test['Date']=test['Date']\n",
    "result_test['StoreID']=test['StoreID']\n",
    "result_test['RegionID']=test['Region']\n",
    "result_test['SalesPredicted']=y_pred_test\n",
    "\n",
    "result_test['Date'] = result_test['Date'].map(transform_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "        \n",
    "result_test.loc[:, ['StoreID', 'Date', 'SalesPredicted']].apply(estimate_sales, axis=1)\n",
    "\n",
    "d1 = {'StoreID':[], 'Month':[], 'NumberOfSales':[]}\n",
    "\n",
    "for s,m in d.keys():\n",
    "    d1['StoreID'].append(s)\n",
    "    d1['Month'].append(m)\n",
    "    d1['NumberOfSales'].append(d[(s,m)])\n",
    "    \n",
    "final_result_test = pd.DataFrame(d1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_result_test.to_csv(\"final_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
