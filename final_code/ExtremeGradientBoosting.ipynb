{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "#import xgboost as xgb\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.datasets import make_regression\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the training set and the validation set which have been already preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing dataset\n",
    "train = pd.read_csv(\"dataset/rand/train_rand_noout3.csv\")\n",
    "val1 = pd.read_csv(\"dataset/rand/train_val1_rand.csv\")\n",
    "val2 = pd.read_csv(\"dataset/rand/train_val2_rand.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the training input samples and the labels for all the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=train.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "X_val1=val1.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0'], axis=1)\n",
    "X_val2=val2.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0'], axis=1)\n",
    "\n",
    "y=train['NumberOfSales']\n",
    "y_val1=val1['NumberOfSales']\n",
    "y_val2=val2['NumberOfSales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to find good hyperparameter in xGBoost. First of all we try to find good values for max_depth and colsample_bytree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=  17  colsample_bytree=  0.675  rmse=  514.633774552173  mae=  335.672759794\n",
      "max_depth=  17  colsample_bytree=  0.65  rmse=  513.7299575563651  mae=  335.632454715\n",
      "max_depth=  17  colsample_bytree=  0.7  rmse=  514.6278905577572  mae=  335.107118267\n",
      "best_mae= 335.107118267  best_max_depth= 12  best_colsample_by_tree= 0.9\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "eta=0.3\n",
    "min_child_weight=5\n",
    "gamma=0\n",
    "subsample=0.6\n",
    "n_estimators=100\n",
    "\n",
    "best_mae = 10000000\n",
    "\n",
    "for depth in range(17,24,3):\n",
    "    for col in {0.7,0.65,0.675}:\n",
    "        xclas = XGBRegressor(subsample=subsample, eta=eta, max_depth=depth, \n",
    "                             colsample_bytree=col, nthread=4,\n",
    "                             min_child_weight=min_child_weight, gamma=gamma,\n",
    "                             n_estimators=n_estimators)  \n",
    "        xclas.fit(X, y)   \n",
    "        y_pred = xclas.predict(X_val1) \n",
    "        mae_val1=mean_absolute_error(y_val1,y_pred)\n",
    "\n",
    "        if mae_val1 < best_mae:\n",
    "            best_mae = mae_val1\n",
    "            best_max_depth = max_depth\n",
    "            best_colsample_by_tree = colsample_by_tree\n",
    "\n",
    "        print(\"max_depth= \", depth, \" colsample_bytree= \", col, \" mae= \", mae_val1)\n",
    "        \n",
    "print(\"best_mae=\", best_mae, \" best_max_depth=\", best_max_depth, \" best_colsample_by_tree=\", best_colsample_by_tree  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check if removing some features we obtain a lower validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsHoliday 520.2090209326052 336.502975056\n",
      "HasPromotions 556.9820967945254 365.496848259\n",
      "StoreType 519.6220065073798 341.574411116\n",
      "NearestCompetitor 517.8847470841648 339.763980609\n",
      "Region_AreaKM2 515.2034300479282 336.61274969\n",
      "Region_GDP 513.5311009343626 336.925736655\n",
      "Region_PopulationK 514.061612857366 336.667751727\n",
      "CloudCover 513.3580694252995 336.021242876\n",
      "Max_Dew_PointC 512.6506558231049 336.009807515\n",
      "Max_Gust_SpeedKm_h 513.1313184914924 335.91962265\n",
      "Max_Humidity 513.453585679261 336.200499994\n",
      "Max_Sea_Level_PressurehPa 513.6683648970707 335.954085276\n",
      "Max_TemperatureC 514.8713276014958 336.760992984\n",
      "Max_VisibilityKm 513.3149456386818 335.456215553\n",
      "Max_Wind_SpeedKm_h 512.9964863530482 335.536146759\n",
      "Mean_Dew_PointC 513.864458185659 336.253077594\n",
      "Mean_Humidity 515.1181959377101 336.625094597\n",
      "Mean_Sea_Level_PressurehPa 512.8867227279862 336.315754529\n",
      "Mean_TemperatureC 512.3679006390973 336.141213256\n",
      "Mean_VisibilityKm 513.506044481011 336.350260857\n",
      "Mean_Wind_SpeedKm_h 513.0731087676451 335.938856626\n",
      "Min_Dew_PointC 510.8650123633667 335.195175338\n",
      "Min_Humidity 512.8298197390397 335.869643176\n",
      "Min_Sea_Level_PressurehPa 514.4037384367241 337.174739029\n",
      "Min_TemperatureC 511.7054595740572 336.143602216\n",
      "Min_VisibilitykM 512.2618985317014 335.457629581\n",
      "Precipitationmm 514.2988453023926 336.827723228\n",
      "WindDirDegrees 512.003581672994 335.108569754\n",
      "AssortmentType_With Fish Department 515.4890846506536 336.597724964\n",
      "AssortmentType_With Non-Food Department 513.1304721408536 335.808405307\n",
      "Rain 512.7228383878381 337.027055983\n",
      "Snow 513.8009581356212 336.974438784\n",
      "Fog 512.5245853296458 336.304937771\n",
      "Hail 513.060755314664 336.001410588\n",
      "Thunderstorm 513.6630420813037 336.139914793\n",
      "IsSaturday 524.4301711507778 344.110688872\n",
      "IsSunday 533.2245788338571 343.309066049\n",
      "OrdinalDate 539.7461145609934 355.631479859\n",
      "WasOpenYesterday 529.6118566854663 347.030430242\n",
      "IsOpenTomorrow 518.0932711315913 339.980904969\n",
      "MeanMonthSales 521.1399216524482 341.243397353\n",
      "MeanStoreSales 518.9144530710488 340.015027776\n",
      "StdStoreSales 523.236567647144 341.550393273\n"
     ]
    }
   ],
   "source": [
    "nt=100\n",
    "col = 0.7\n",
    "depth=17\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "for feature in feature_names:\n",
    "    \n",
    "    X=train.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "    X_val1=val.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0'], axis=1)\n",
    "    X=X.drop([feature], axis=1)\n",
    "    X_val1=X_val1.drop([feature], axis=1)\n",
    "    \n",
    "    xclas = XGBRegressor(subsample=subsample, eta=eta, max_depth=depth, \n",
    "                         colsample_bytree=col, nthread=4,\n",
    "                         min_child_weight=min_child_weight, gamma=gamma,\n",
    "                         n_estimators=n_estimators)  \n",
    "    xclas.fit(X, y)   \n",
    "    y_pred = xclas.predict(X_val1) \n",
    "    mae_val1=mean_absolute_error(y_val1,y_pred)\n",
    "    print(feature, mae_val1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we optimize the number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators=  175  rmse= 509.0978732254196 331.274821861\n",
      "n_estimators=  185  rmse= 508.7408707211783 331.297567501\n",
      "n_estimators=  195  rmse= 508.63967319446175 331.22868695\n",
      "n_estimators=  205  rmse= 508.71005515048637 331.314007034\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b1c0e881b311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                          n_estimators=n_estimators)  \n\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mxclas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxclas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmse_val1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programmi\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    291\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                               verbose_eval=verbose, xgb_model=xgb_model)\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programmi\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programmi\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programmi\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 895\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eta=0.3\n",
    "min_child_weight=5\n",
    "gamma=0\n",
    "subsample=0.6\n",
    "best_max_depth=17\n",
    "best_colsample_bytree=0.7\n",
    "best_mae = 10000000\n",
    "\n",
    "X=train.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "X_val1=val.drop(['StoreID','Date', 'NumberOfSales', 'Region','Unnamed: 0'], axis=1)\n",
    "\n",
    "for n_estimators in range(175, 226, 10):\n",
    "    \n",
    "    xclas = XGBRegressor(subsample=subsample, eta=eta, max_depth=best_max_depth, \n",
    "                         colsample_bytree=best_colsample_bytree, nthread=4,\n",
    "                         min_child_weight=min_child_weight, gamma=gamma,\n",
    "                         n_estimators=n_estimators)  \n",
    "    \n",
    "    xclas.fit(X, y)   \n",
    "    y_pred = xclas.predict(X_val1) \n",
    "    mae_val1=mean_absolute_error(y_val1,y_pred)\n",
    "\n",
    "    if mae_val1 < best_mae:\n",
    "        best_mae = mae_val1\n",
    "        best_n_estimators = n_estimators\n",
    "\n",
    "    print(\"n_estimators= \", n_estimators, \" rmse=\", mae_val1)\n",
    "        \n",
    "print(\"best_mae =\", best_mae, \" best_n_estimators = \", n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we predict the second validation set and we compute the mean square error and the mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_val2= 558.791235742\n"
     ]
    }
   ],
   "source": [
    "best_depth = 17\n",
    "best_colsample = 0.7\n",
    "best_n_estimators = 200\n",
    "eta=0.3\n",
    "min_child_weight=5\n",
    "gamma=0\n",
    "subsample=0.6\n",
    "\n",
    "xclas = XGBRegressor(subsample=subsample, eta=eta, max_depth=best_depth, \n",
    "                         colsample_bytree=best_colsample, nthread=4,\n",
    "                         min_child_weight=min_child_weight, gamma=gamma,\n",
    "                         n_estimators=best_n_estimators)  \n",
    "\n",
    "xclas.fit(X, y)   \n",
    "y_pred_val2 = xclas.predict(X_val2) \n",
    "mae_val2=mean_absolute_error(y_val2,y_pred_val2)\n",
    "print(\"mae_val2=\",mae_val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end we save the predicted values in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns=['Date', 'StoreID', 'RegionID', 'SalesPredicted', 'SalesReal']\n",
    "index=range(y_val2.shape[0])\n",
    "result=pd.DataFrame(index=index,columns=columns)\n",
    "\n",
    "result['Date']=val2['Date']\n",
    "result['StoreID']=val2['StoreID']\n",
    "result['RegionID']=val2['Region']\n",
    "result['SalesPredicted']=y_pred_val2\n",
    "result['SalesReal']=y_val2\n",
    "\n",
    "result.to_csv(\"results.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
